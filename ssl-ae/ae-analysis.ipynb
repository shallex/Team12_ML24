{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca11041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from misc.datasets_ae import *\n",
    "\n",
    "from umap import UMAP\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import scipy\n",
    "import skdim\n",
    "\n",
    "# seeding\n",
    "SEED = 91\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e989d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_from_region__numfound(stat_for_mask, stat_mean, \n",
    "                         eps, \n",
    "                         eps_max,\n",
    "                         n,\n",
    "                         eps_step=2e-5,\n",
    "                         patience=1e+5,\n",
    "                        ):\n",
    "    \n",
    "    assert len(stat_for_mask) > n, \"'n' >= Max number of values in stat\"\n",
    "    \n",
    "    mask_out = (stat_for_mask < (stat_mean+eps)) * (stat_for_mask > (stat_mean-eps))\n",
    "    \n",
    "    counter = 0\n",
    "    while (sum(mask_out) < n) and (eps <= eps_max) and (counter < patience):\n",
    "        eps += eps_step\n",
    "        mask_out = (stat_for_mask < (stat_mean+eps)) * (stat_for_mask > (stat_mean-eps))\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "    n_found = sum(mask_out)\n",
    "    return mask_out, n_found\n",
    "\n",
    "def get_num_samples_in_interval(\n",
    "    stat_for_mask, \n",
    "    stat_mean, \n",
    "    eps_max,\n",
    "): \n",
    "    mask_out = (stat_for_mask < (stat_mean+eps_max)) * (stat_for_mask > (stat_mean-eps_max))\n",
    "    n_found = sum(mask_out)\n",
    "    \n",
    "    return n_found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1faf853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_zoom_for_stat__imghist(stat_values, thr_l, thr_r,\n",
    "                           name_stat,\n",
    "                           N_IMG_ZOOM=3, \n",
    "                           N_IMG_PER_ZOOM=3,\n",
    "                           figsize=(6,6),\n",
    "                           log_hist_y = False,\n",
    "                          ):\n",
    "\n",
    "    sil_scores = stat_values\n",
    "    stat_for_mask = stat_values\n",
    "    \n",
    "    right_thr_l__zoom = thr_l\n",
    "    right_thr_r__zoom = thr_r\n",
    "    eps_start__zoom = 1e-5\n",
    "\n",
    "    sil_scores_2_plot = np.linspace(right_thr_l__zoom, right_thr_r__zoom, N_IMG_ZOOM)\n",
    "\n",
    "    #####\n",
    "    fig, ax = plt.subplots(figsize=(16,5))\n",
    "    for x_i in sil_scores_2_plot:\n",
    "        ax.axvline(x_i, 0, 1000, c='darkorange', linestyle='dashed')\n",
    "\n",
    "    ax.hist(sil_scores, bins=N_IMG_ZOOM)\n",
    "    ax.set_xlim(thr_l-(0.01*(thr_r-thr_l)), 1.01*thr_r)\n",
    "    if log_hist_y:\n",
    "        ax.set_yscale('log')\n",
    "    x_start, x_end = ax.get_xlim()\n",
    "    ax.xaxis.set_ticks(np.linspace(x_start, x_end, max(N_IMG_ZOOM//2, 5)))\n",
    "    ax.tick_params(axis='x', rotation=70)\n",
    "    plt.show()\n",
    "\n",
    "    #####\n",
    "    right_tale_mask__zoomed = stat_for_mask > right_thr_l__zoom\n",
    "    right_tale__zoomed = idx_bed[right_tale_mask__zoomed]\n",
    "    \n",
    "    #####\n",
    "    img_per_col = N_IMG_PER_ZOOM\n",
    "\n",
    "    sil_region_mask_list = []\n",
    "    n_found_list = []\n",
    "    for i, stat_score_ in tqdm(enumerate(sil_scores_2_plot)):\n",
    "        sil_region_mask, _ = get_mask_from_region__numfound(\n",
    "            stat_values, stat_score_, eps_start__zoom, \n",
    "            eps_max=(sil_scores_2_plot[1]-sil_scores_2_plot[0])/2,\n",
    "            eps_step=1e-2*(sil_scores_2_plot[1]-sil_scores_2_plot[0])/2,\n",
    "            n=img_per_col,\n",
    "        )\n",
    "        n_found = get_num_samples_in_interval(\n",
    "            stat_values, stat_score_,\n",
    "            eps_max=(sil_scores_2_plot[1]-sil_scores_2_plot[0])/2,\n",
    "        )\n",
    "        \n",
    "        sil_region_mask_list.append(sil_region_mask)\n",
    "        n_found_list.append(n_found)\n",
    "\n",
    "    # Plot images like histogram\n",
    "    # Norm number of images scaled by found in the region \n",
    "    n_found_list = np.array(n_found_list)\n",
    "    # take log to smooth \n",
    "    n_found_list = np.log1p(n_found_list)\n",
    "    n_found_max = np.max(n_found_list)\n",
    "    # max number of imgs*N_IMG_PER_ZOOM to plot for a region\n",
    "    n_found_list_coef = n_found_list / n_found_max \n",
    "    \n",
    "    f, axes = plt.subplots(img_per_col, len(sil_scores_2_plot), figsize=figsize)\n",
    "    \n",
    "    for i, (stat_score_, sil_region_mask, n_found_coef) in enumerate(zip(\n",
    "        sil_scores_2_plot, sil_region_mask_list, n_found_list_coef\n",
    "    )):     \n",
    "        ax_col = axes[:, i]\n",
    "        \n",
    "        idx_zoom = idx_bed[sil_region_mask]\n",
    "        np.random.shuffle(idx_zoom)\n",
    "\n",
    "        for j in np.arange(img_per_col):\n",
    "            ax_ij = ax_col[j]\n",
    "\n",
    "            if (j >= len(idx_zoom)):\n",
    "                ax_ij.set_title(f\"None\\n{stat_score_:.3e}\", fontsize=8)\n",
    "            else:\n",
    "                if j == np.floor(n_found_coef*N_IMG_PER_ZOOM):\n",
    "                    ax_ij.set_title(f\"None\\n{stat_score_:.3e}\", fontsize=8)\n",
    "                else:\n",
    "                    if (j > np.floor(n_found_coef*N_IMG_PER_ZOOM)):\n",
    "                        c_map_str = 'gray'\n",
    "                    else: \n",
    "                        c_map_str = 'viridis'\n",
    "                    ax_ij.imshow(train_dataset_sums[idx_zoom[j]][0][0], cmap=c_map_str)\n",
    "                    ax_ij.set_title(f\"{train_dataset_sums[idx_zoom[j]][1]}\\n{sil_scores[idx_zoom[j]]:.3e}\", fontsize=8)\n",
    "\n",
    "\n",
    "    f.suptitle(f'Images along {name_stat}\\n[{thr_l:.3e} - {thr_r:.3e}]', fontsize=20)\n",
    "    for ax in axes.ravel():\n",
    "        ax.set_axis_off()   \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f128a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_filename = \"bn_logits_10_600_wimgsums.npy\"\n",
    "\n",
    "results_path = os.path.join(\"MNIST\", \"results\")\n",
    "logits_path = os.path.join(results_path, logits_filename)\n",
    "\n",
    "data = np.load(logits_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868fbcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_dataset = MNIST(root=\"./.cache\", download=True,  transform=image_transform)\n",
    "\n",
    "aug_ratio = 0.1\n",
    "train_dataset_sums = MNIST_w_imagesums(train_dataset, aug_ratio=aug_ratio)\n",
    "\n",
    "\n",
    "id_new_full = train_dataset_sums.idxs_aug_full\n",
    "id_new = train_dataset_sums.idxs_aug\n",
    "\n",
    "idx_bed = np.arange(len(train_dataset_sums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d30a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = np.array([train_dataset_sums[i][0][0].numpy() for i in range(len(train_dataset_sums))])\n",
    "train_labels = np.array([y_ for _, y_ in train_dataset_sums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d52d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb69b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_new_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9953a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6660fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_saved = np.load(r\"C:\\Users\\MQTyor\\ai_pc\\Skoltech-ai-courses\\ML term 3\\Project\\work\\ae code\\v2\\Team12_ML24\\ssl-ae\\MNIST\\results\\img_indices_10_600_wimgsums.npy\")\n",
    "idxs_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f975bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_img[1+1+54000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1a69c3",
   "metadata": {},
   "source": [
    "# 2D Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a6ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_2d = UMAP(\n",
    "    n_components=2, \n",
    "#     init='random', \n",
    "#     random_state=SEED\n",
    ")\n",
    "\n",
    "projector =  umap_2d\n",
    "\n",
    "\n",
    "# last epoch embeddings\n",
    "data_project = data[-1]\n",
    "\n",
    "proj_2d = projector.fit_transform(data_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d1e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2D plane of embeddings with augmented\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "f, axes = plt.subplots(1, 3, figsize=(20,6))\n",
    "\n",
    "# With augmented images\n",
    "lbl_enc = LabelEncoder()\n",
    "labels_ordinal = lbl_enc.fit_transform(train_labels[:])\n",
    "scat = axes[0].scatter(\n",
    "    proj_2d[:,0][:], \n",
    "    proj_2d[:,1][:], \n",
    "    c=labels_ordinal, \n",
    "    label=labels_ordinal,\n",
    "    cmap='Spectral'\n",
    ")\n",
    "axes[0].legend(*scat.legend_elements(), fontsize=9, loc='lower left')\n",
    "axes[0].set_title('Original+Distorted images')\n",
    "\n",
    "print(f\"All classes with augmentations:\\n{lbl_enc.classes_}\")\n",
    "\n",
    "\n",
    "# Without augmented images\n",
    "idx_no_sums = np.arange(0, 60_000*0.9, 1, dtype=int)\n",
    "idx_plot = idx_no_sums\n",
    "lbl_enc = LabelEncoder()\n",
    "labels_ordinal = lbl_enc.fit_transform(train_labels[idx_plot])\n",
    "scat = axes[1].scatter(\n",
    "    proj_2d[:,0][idx_plot], \n",
    "    proj_2d[:,1][idx_plot], \n",
    "    c=labels_ordinal, \n",
    "    label=labels_ordinal,\n",
    "    cmap='Spectral'\n",
    ")\n",
    "axes[1].legend(*scat.legend_elements(), fontsize=9, loc='lower left')\n",
    "axes[1].set_title('Original images')\n",
    "\n",
    "# Only augmented images\n",
    "idx_no_sums = np.arange(60_000*0.9, 60_000*0.95, 1, dtype=int)\n",
    "idx_plot = idx_no_sums\n",
    "lbl_enc = LabelEncoder()\n",
    "labels_ordinal = lbl_enc.fit_transform(train_labels[idx_plot])\n",
    "scat = axes[2].scatter(\n",
    "    proj_2d[:,0][idx_plot], \n",
    "    proj_2d[:,1][idx_plot], \n",
    "    c=labels_ordinal, \n",
    "    label=labels_ordinal,\n",
    "    cmap='Spectral'\n",
    ")\n",
    "axes[2].legend(*scat.legend_elements(), fontsize=9, loc='lower left')\n",
    "axes[2].set_title('Distorted images')\n",
    "\n",
    "for ax_i in axes:\n",
    "    ax_i.set_xlim(-8, 15)\n",
    "    ax_i.set_ylim(-8, 18)\n",
    "\n",
    "plt.suptitle('2D UMAP Projection of the Bottleneck layer activations', fontsize=16)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c47dfb0",
   "metadata": {},
   "source": [
    "# Sample-wise metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b54d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(index=id_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214339d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_scores_arr = []\n",
    "def func_par(x_cluster):\n",
    "    cluster_model = KMeans(n_clusters=10, random_state=SEED, max_iter=200)\n",
    "    clusters_pred = cluster_model.fit_predict(x_cluster)\n",
    "    sil_scores = silhouette_samples(x_cluster, clusters_pred)\n",
    "    return sil_scores\n",
    "# Only every 10th epoch\n",
    "results = Parallel(n_jobs=-1)\\\n",
    "    (delayed(func_par)(x_cluster) for x_cluster in tqdm(data[::10]))\n",
    "sil_scores_arr = np.array(results)\n",
    "metrics_df['sil_score__last'] = sil_scores_arr[-1]\n",
    "metrics_df['sil_score__std_from10'] = sil_scores_arr[0:].std(axis=0)\n",
    "metrics_df['sil_score__mean_from0'] = sil_scores_arr[0:].mean(axis=0)\n",
    "\n",
    "dif = data[1:] - data[:-1]\n",
    "l1_norm = np.linalg.norm(dif, ord=1, axis=2)\n",
    "metrics_df['dif_L1__std_from0'] = l1_norm[0:].std(axis=0)\n",
    "metrics_df['dif_L1__var_from0'] = l1_norm[0:].var(axis=0)\n",
    "metrics_df['dif_L1__mean_from0'] = l1_norm[0:].mean(axis=0)\n",
    "\n",
    "stat_l2 = np.linalg.norm(dif, ord=2, axis=2)\n",
    "metrics_df['dif_L2__std_from0'] = stat_l2[0:].std(axis=0)\n",
    "metrics_df['dif_L2__var_from0'] = stat_l2[0:].var(axis=0)\n",
    "metrics_df['dif_L2__mean_from0'] = stat_l2[0:].mean(axis=0)\n",
    "\n",
    "l2_embs = np.linalg.norm(data, ord=2, axis=2)\n",
    "metrics_df['L2__last'] = l2_embs[-1]\n",
    "metrics_df['L2__var_from0'] = l2_embs[0:].var(axis=0)\n",
    "metrics_df['L2__var_from20'] = l2_embs[20:].var(axis=0)\n",
    "metrics_df['L2__var_from250'] = l2_embs[250:].var(axis=0)\n",
    "metrics_df['L2__std_from0'] = l2_embs[0:].std(axis=0)\n",
    "metrics_df['L2__std_from20'] = l2_embs[20:].std(axis=0)\n",
    "metrics_df['L2__std_from250'] = l2_embs[250:].std(axis=0)\n",
    "metrics_df['L2__mean_from0'] = l2_embs[0:].mean(axis=0)\n",
    "metrics_df['L2__mean_from20'] = l2_embs[20:].mean(axis=0)\n",
    "\n",
    "lid_estimator = skdim.id.TLE()\n",
    "lid_tle_list = []\n",
    "for epoch_i in tqdm(range(10,len(data),10)):\n",
    "    lid_tle = lid_estimator.fit_transform_pw(\n",
    "        X=data[epoch_i],\n",
    "        n_jobs=-1,\n",
    "        n_neighbors=30\n",
    "    )\n",
    "    lid_tle_list.append(lid_tle)\n",
    "lid_tle_list = np.array(lid_tle_list)  \n",
    "metrics_df[\"LID__last\"] = lid_tle_list[-1]\n",
    "metrics_df[\"LID__var_from_10\"] = lid_tle_list[:].var(axis=0)\n",
    "metrics_df[\"LID__std_from_10\"] = lid_tle_list[:].std(axis=0)\n",
    "metrics_df[\"LID__mean_from_10\"] = lid_tle_list[:].mean(axis=0)\n",
    "\n",
    "\n",
    "stat_h = scipy.stats.entropy(\n",
    "    pk=data,\n",
    "    axis=2,\n",
    ")\n",
    "metrics_df[\"H__last\"] = stat_h[-1]\n",
    "metrics_df[\"H__diff_last_250\"] = stat_h[-1]-stat_h[250]\n",
    "metrics_df[\"H__diff_last_450\"] = stat_h[-1]-stat_h[450]\n",
    "metrics_df[\"H__var_from_0\"] = stat_h[0:].var(axis=0)\n",
    "metrics_df[\"H__var_from_450\"] = stat_h[450:].var(axis=0)\n",
    "metrics_df[\"H__std_from_0\"] = stat_h[0:].std(axis=0)\n",
    "metrics_df[\"H__std_from_450\"] = stat_h[450:].std(axis=0)\n",
    "metrics_df[\"H__mean_from_0\"] = stat_h[0:].mean(axis=0)\n",
    "metrics_df[\"H__mean_from_400\"] = stat_h[400:].mean(axis=0)\n",
    "\n",
    "metrics_df.to_csv('metrics_600.csv', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c63be42",
   "metadata": {},
   "source": [
    "## 1) Silhouette for 10 clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f86ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sil_scores_arr = []\n",
    "\n",
    "# def func_par(x_cluster):\n",
    "#     cluster_model = KMeans(n_clusters=10, random_state=SEED, max_iter=200)\n",
    "#     clusters_pred = cluster_model.fit_predict(x_cluster)\n",
    "#     sil_scores = silhouette_samples(x_cluster, clusters_pred)\n",
    "#     return sil_scores\n",
    "\n",
    "# # Only every 10th epoch\n",
    "# results = Parallel(n_jobs=-1)\\\n",
    "#     (delayed(func_par)(x_cluster) for x_cluster in tqdm(data[::10]))\n",
    "    \n",
    "# sil_scores_arr = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35ca0d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.title(f\"Sil scores at {10*i} epoch\")\n",
    "    plt.hist(sil_scores_arr[i,:-3000], bins=100);\n",
    "    plt.hist(sil_scores_arr[i,-3000:], bins=100);\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    plt.yscale('log')\n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(sil_scores_arr))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd49eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(f\"Sil scores at {100} epoch\")\n",
    "plt.hist(sil_scores_arr[10,:-3000], bins=100);\n",
    "plt.hist(sil_scores_arr[10,-3000:], bins=100);\n",
    "plt.legend([\"Original\", 'Distorted'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803288e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(f\"Sil scores at {600} epoch\")\n",
    "plt.hist(sil_scores_arr[-1,:-3000], bins=100);\n",
    "plt.hist(sil_scores_arr[-1,-3000:], bins=100);\n",
    "plt.legend([\"Original\", 'Distorted'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1023e5",
   "metadata": {},
   "source": [
    "> Seems well because the augmeneted images are not separable from the very beginning BASED on the Sil score on that epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a45670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.title(10*i)\n",
    "    plt.hist(sil_scores_arr[i:,:-3000].std(axis=0), bins=100);\n",
    "    plt.hist(sil_scores_arr[i:,-3000:].std(axis=0), bins=100);\n",
    "    plt.title(f\"Std of Sil scores starting from {10*i} epoch\")\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    plt.yscale('log')\n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(sil_scores_arr))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45343ed3",
   "metadata": {},
   "source": [
    "> Seems well because the augmeneted images are separable from the very beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43497e8",
   "metadata": {},
   "source": [
    "#### Mean of Sil score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d696bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.title(10*i)\n",
    "    plt.hist(sil_scores_arr[i:,:-3000].mean(axis=0), bins=100);\n",
    "    plt.hist(sil_scores_arr[i:,-3000:].mean(axis=0), bins=100);\n",
    "    plt.title(f\"Mean of Sil scores starting from {10*i} epoch\")\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    plt.yscale('log')\n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(sil_scores_arr))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998aeeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_plot = sil_scores_arr[0:].mean(axis=0)\n",
    "\n",
    "plot_img_zoom_for_stat__imghist(\n",
    "    stat_values=stat_plot,\n",
    "    thr_l=stat_plot.min(),\n",
    "    thr_r=stat_plot.max(),\n",
    "    name_stat=\"Mean starting from 0 epoch (epochs) of Silhouette score (emb_size) of samples\",\n",
    "    figsize=(50,30),\n",
    "    N_IMG_ZOOM=40,\n",
    "    N_IMG_PER_ZOOM=15,\n",
    "    log_hist_y=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f30ab",
   "metadata": {},
   "source": [
    "### Adding metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6465c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_df['sil_score__last'] = sil_scores_arr[-1]\n",
    "\n",
    "# metrics_df['sil_score__std_from10'] = sil_scores_arr[0:].std(axis=0)\n",
    "\n",
    "# metrics_df['sil_score__mean_from0'] = sil_scores_arr[0:].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27abfd80",
   "metadata": {},
   "source": [
    "## 2) Difference between embeddings of adjacent epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86daf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # emb_t - emb_(t-1)\n",
    "# dif = data[1:] - data[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d7092c",
   "metadata": {},
   "source": [
    "### 2.1) L1 norm - difference bw adj embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcd9c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = np.linalg.norm(dif, ord=1, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc09a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(stat[i,:-3000], bins=100);\n",
    "    plt.hist(stat[i,-3000:], bins=100);\n",
    "    plt.title(f\"L1 norm of difference of adj embs at {i} epoch\")\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    plt.yscale('log')\n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(stat))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e51edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(stat[i:,:-3000].std(axis=0), bins=100);\n",
    "    plt.hist(stat[i:,-3000:].std(axis=0), bins=100);\n",
    "    plt.title(f\"Std of L1 norm of difference of adj embs after {i} epoch\")\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(stat))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2445188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(stat[i:,:-3000].mean(axis=0), bins=100);\n",
    "    plt.hist(stat[i:,-3000:].mean(axis=0), bins=100);\n",
    "    plt.title(f\"Mean of L1 norm of difference of adj embs after {i} epoch\")\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(stat))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd8e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1_norm = np.linalg.norm(dif, ord=1, axis=2)\n",
    "# metrics_df['dif_L1__std_from0'] = l1_norm[0:].std(axis=0)\n",
    "# metrics_df['dif_L1__var_from0'] = l1_norm[0:].var(axis=0)\n",
    "# metrics_df['dif_L1__mean_from0'] = l1_norm[0:].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeb111e",
   "metadata": {},
   "source": [
    "### 2.2) L2 norm of difference bw adj embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7885ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2norm = np.linalg.norm(dif, ord=2, axis=2)\n",
    "stat = l2norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae336dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(l2norm[i,:-3000], bins=100);\n",
    "    plt.hist(l2norm[i,-3000:], bins=100);\n",
    "    plt.title(f\"L2 norm of difference of adj embs at {i} epoch\")\n",
    "#     plt.xlim(stat.min(), stat.max())\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(stat))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb9661",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(l2norm[i:,:-3000].std(axis=0), bins=100);\n",
    "    plt.hist(l2norm[i:,-3000:].std(axis=0), bins=100);\n",
    "    plt.title(f\"Std of L2 norm of difference of adj embs after {i} epoch\")\n",
    "#     plt.xlim(stat.min(), stat.mean() + 4*stat.std())\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(stat))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16640142",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(l2norm[i:,:-3000].mean(axis=0), bins=100);\n",
    "    plt.hist(l2norm[i:,-3000:].mean(axis=0), bins=100);\n",
    "    plt.title(f\"Mean of L2 norm of difference of adj embs after {i} epoch\")\n",
    "#     plt.xlim(stat.min(), stat.mean() + 4*stat.std())\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(stat))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e363217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat_l2 = np.linalg.norm(dif, ord=2, axis=2)\n",
    "# metrics_df['dif_L2__std_from0'] = stat_l2[0:].std(axis=0)\n",
    "# metrics_df['dif_L2__var_from0'] = stat_l2[0:].var(axis=0)\n",
    "# metrics_df['dif_L2__mean_from0'] = stat_l2[0:].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec4c210",
   "metadata": {},
   "source": [
    "### 2.3) Mean of diff of adj embs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a3000",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = np.mean(dif, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4662b749",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(stat[i,:-3000], bins=100);\n",
    "    plt.hist(stat[i,-3000:], bins=100);\n",
    "    plt.title(f\"Mean of difference of adj embs at {i} epoch\")\n",
    "#     plt.xlim(stat.mean()-4*stat.std(), stat.mean()+4*stat.std())\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(stat))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3638913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(stat[i:,:-3000].mean(axis=0), bins=100);\n",
    "    plt.hist(stat[i:,-3000:].mean(axis=0), bins=100);\n",
    "    plt.title(f\"Mean of mean of difference of adj embs from {i} epoch\")\n",
    "#     plt.xlim(stat.mean()-4*stat.std(), stat.mean()+4*stat.std())\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(stat))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3090a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(stat[i:,:-3000].std(axis=0), bins=100);\n",
    "    plt.hist(stat[i:,-3000:].std(axis=0), bins=100);\n",
    "    plt.title(f\"Std of mean of difference of adj embs from {i} epoch\")\n",
    "#     plt.xlim(\n",
    "#         stat.std(axis=0).mean()-4*stat.std(axis=0).std(), \n",
    "#         stat.std(axis=0).mean()+4*stat.std(axis=0).std()\n",
    "#     )\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(stat))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ade8ab",
   "metadata": {},
   "source": [
    "## 3) L2 of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_embs = np.linalg.norm(data, ord=2, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = l2_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa689b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_plot = np.random.choice(l2_embs.shape[1], size=150, replace=False, )\n",
    "\n",
    "plt.figure(figsize=(20,3))\n",
    "plt.plot(l2_embs[:, idx_plot])\n",
    "plt.title(\"L2 norm of BN embeddings of randomly sampled objects\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e012f7",
   "metadata": {},
   "source": [
    "### 3.1) at i epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e3d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(stat[i,:-3000], bins=100);\n",
    "    plt.hist(stat[i,-3000:], bins=100);\n",
    "    plt.title(f\"L2 of embs at {i} epoch\")\n",
    "#     plt.xlim(stat.mean()-4*stat.std(), stat.mean()+4*stat.std())\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(stat))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f1940",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(stat[i:,:-3000].mean(axis=0), bins=100);\n",
    "    plt.hist(stat[i:,-3000:].mean(axis=0), bins=100);\n",
    "    plt.title(f\"Mean of L2 norm of embs from {i} epoch\")\n",
    "#     plt.xlim(stat.mean()-4*stat.std(), stat.mean()+4*stat.std())\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(stat))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6901581",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(stat[i:,:-3000].std(axis=0), bins=100);\n",
    "    plt.hist(stat[i:,-3000:].std(axis=0), bins=100);\n",
    "    plt.title(f\"Std of L2 norm of embs from {i} epoch\")\n",
    "#     plt.xlim(\n",
    "#         stat.std(axis=0).mean()-4*stat.std(axis=0).std(), \n",
    "#         stat.std(axis=0).mean()+4*stat.std(axis=0).std()\n",
    "#     )\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(stat))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4557b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_df['L2__last'] = l2_embs[-1]\n",
    "\n",
    "# metrics_df['L2__var_from0'] = l2_embs[0:].var(axis=0)\n",
    "# metrics_df['L2__var_from20'] = l2_embs[20:].var(axis=0)\n",
    "# metrics_df['L2__var_from250'] = l2_embs[250:].var(axis=0)\n",
    "\n",
    "# metrics_df['L2__std_from0'] = l2_embs[0:].std(axis=0)\n",
    "# metrics_df['L2__std_from20'] = l2_embs[20:].std(axis=0)\n",
    "# metrics_df['L2__std_from250'] = l2_embs[250:].std(axis=0)\n",
    "\n",
    "# metrics_df['L2__mean_from0'] = l2_embs[0:].mean(axis=0)\n",
    "# metrics_df['L2__mean_from20'] = l2_embs[20:].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ee115",
   "metadata": {},
   "source": [
    "## 4) Intrinsic Dim of layer ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c789bde2",
   "metadata": {},
   "source": [
    "### 4.1) Int dim "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ab1a59",
   "metadata": {},
   "source": [
    "#### 4.1.1) TLE - skdim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89785f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# lid_estimator = skdim.id.TLE()\n",
    "\n",
    "# lid_tle_list = []\n",
    "\n",
    "# for epoch_i in tqdm(range(0,len(data),10)):\n",
    "#     lid_tle = lid_estimator.fit_transform_pw(\n",
    "#         X=data[epoch_i],\n",
    "#         n_jobs=-1,\n",
    "#         n_neighbors=30\n",
    "#     )\n",
    "    \n",
    "#     lid_tle_list.append(lid_tle)\n",
    "    \n",
    "# lid_tle_list = np.array(lid_tle_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab229b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lid_estimator = skdim.id.TLE()\n",
    "# lid_tle_list = []\n",
    "# for epoch_i in tqdm(range(10,len(data),10)):\n",
    "#     lid_tle = lid_estimator.fit_transform_pw(\n",
    "#         X=data[epoch_i],\n",
    "#         n_jobs=-1,\n",
    "#         n_neighbors=30\n",
    "#     )\n",
    "#     lid_tle_list.append(lid_tle)\n",
    "# lid_tle_list = np.array(lid_tle_list)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79348723",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lid_tle_list[-1,:-3000], bins=100);\n",
    "plt.hist(lid_tle_list[-1,-3000:], bins=100);\n",
    "plt.title(f\"LID of embs at {list(range(0,len(data),10))[-1]} epoch\")\n",
    "plt.yscale('log')\n",
    "plt.legend([\"Original\", 'Distorted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b10045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lid_tle_list[1:,:-3000].std(axis=0), bins=100);\n",
    "plt.hist(lid_tle_list[1:,-3000:].std(axis=0), bins=100);\n",
    "plt.title(f\"STD of LID of embs from {10*1} epoch\")\n",
    "plt.yscale('log')\n",
    "plt.legend([\"Original\", 'Distorted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df4e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lid_tle_list[1:,:-3000].mean(axis=0), bins=100);\n",
    "plt.hist(lid_tle_list[1:,-3000:].mean(axis=0), bins=100);\n",
    "plt.title(f\"Mean of LID of embs from {10*1} epoch\")\n",
    "plt.yscale('log')\n",
    "plt.legend([\"Original\", 'Distorted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ad8ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_plot = lid_tle_list[1:].mean(axis=0)\n",
    "\n",
    "plot_img_zoom_for_stat__imghist(\n",
    "    stat_values=stat_plot,\n",
    "    thr_l=stat_plot.min(),\n",
    "    thr_r=stat_plot.max(),\n",
    "    name_stat=\"Std after 7th epoch (epochs) of loss per sample (emb_size) of samples\",\n",
    "    figsize=(70,25),\n",
    "    N_IMG_ZOOM=60,\n",
    "    N_IMG_PER_ZOOM=15,\n",
    "    log_hist_y=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(lid_tle[:-3000], bins=100);\n",
    "# plt.hist(lid_tle[-3000:], bins=100);\n",
    "    \n",
    "# plt.yscale('log')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7347ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig, ax = plt.subplots()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(lid_tle_list[1:][i,:-3000], bins=100);\n",
    "    plt.hist(lid_tle_list[1:][i,-3000:], bins=100);\n",
    "    plt.title(f\"LID of embs at {100*i} epoch\")\n",
    "    plt.xlim(\n",
    "        lid_tle_list[1:].mean()-4*lid_tle_list[1:].std(), \n",
    "        lid_tle_list[1:].mean()+4*lid_tle_list[1:].std()\n",
    "    )\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(lid_tle_list[1:]))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40185dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_plot = np.random.choice(lid_tle_list.shape[1], size=50, replace=False, )\n",
    "\n",
    "plt.figure(figsize=(20,3))\n",
    "plt.plot(lid_tle_list[1:, idx_plot])\n",
    "plt.title(\"LID of BN layer of randomly sampled objects\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3947e6ff",
   "metadata": {},
   "source": [
    "## 5) Entropy of a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780011cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat_h = scipy.stats.entropy(\n",
    "#     pk=data,\n",
    "#     axis=2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ccdbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_df[\"H__last\"] = stat_h[-1]\n",
    "\n",
    "# metrics_df[\"H__diff_last_250\"] = stat_h[-1]-stat_h[250]\n",
    "# metrics_df[\"H__diff_last_450\"] = stat_h[-1]-stat_h[450]\n",
    "\n",
    "# metrics_df[\"H__var_from_0\"] = stat_h[0:].var(axis=0)\n",
    "# metrics_df[\"H__var_from_450\"] = stat_h[450:].var(axis=0)\n",
    "\n",
    "# metrics_df[\"H__std_from_0\"] = stat_h[0:].std(axis=0)\n",
    "# metrics_df[\"H__std_from_450\"] = stat_h[450:].std(axis=0)\n",
    "\n",
    "# metrics_df[\"H__mean_from_0\"] = stat_h[0:].mean(axis=0)\n",
    "# metrics_df[\"H__mean_from_400\"] = stat_h[400:].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdfe545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_df.to_csv('metrics_600.csv', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb91ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_plot = np.random.choice(stat_h.shape[1], size=50, replace=False, )\n",
    "\n",
    "plt.figure(figsize=(20,3))\n",
    "plt.plot(stat_h[:, idx_plot])\n",
    "plt.title(\"Entropy of BN layer of randomly sampled objects\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ee932b",
   "metadata": {},
   "source": [
    "> The separation with this measure can happen later in epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b050cf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "mean_plot = stat_h.mean()\n",
    "std_plot = stat_h.std()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(stat_h[i:,:-3000].mean(axis=0), bins=100);\n",
    "    plt.hist(stat_h[i:,-3000:].mean(axis=0), bins=100);\n",
    "    plt.title(f\"Mean of Entropy of bottleneck layer from {i} epoch\")\n",
    "    plt.xlim(\n",
    "        mean_plot-4*std_plot, \n",
    "        mean_plot+4*std_plot\n",
    "    )\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(stat_h))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c799e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_plot = stat_h.mean(axis=0)\n",
    "\n",
    "plot_img_zoom_for_stat__imghist(\n",
    "    stat_values=stat_plot,\n",
    "    thr_l=stat_plot.min(),\n",
    "    thr_r=stat_plot.max(),\n",
    "    name_stat=\"Std after 7th epoch (epochs) of loss per sample (emb_size) of samples\",\n",
    "    figsize=(70,25),\n",
    "    N_IMG_ZOOM=60,\n",
    "    N_IMG_PER_ZOOM=15,\n",
    "    log_hist_y=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f757e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "mean_plot = stat_h.std(axis=0).mean()\n",
    "std_plot = stat_h.std(axis=0).std()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(stat_h[i:,:-3000].std(axis=0), bins=100);\n",
    "    plt.hist(stat_h[i:,-3000:].std(axis=0), bins=100);\n",
    "    plt.title(f\"Std of Entropy of bottleneck layer from {i} epoch\")\n",
    "    plt.xlim(\n",
    "        mean_plot-4*std_plot, \n",
    "        mean_plot+4*std_plot\n",
    "    )\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(stat_h))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "mean_plot = stat_h.var(axis=0).mean()\n",
    "std_plot = stat_h.var(axis=0).std()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(stat_h[i:,:-3000].var(axis=0), bins=100);\n",
    "    plt.hist(stat_h[i:,-3000:].var(axis=0), bins=100);\n",
    "    plt.title(f\"Var of Entropy of bottleneck layer from {i} epoch\")\n",
    "#     plt.xlim(\n",
    "#         mean_plot-1*std_plot, \n",
    "#         mean_plot+1*std_plot\n",
    "#     )\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(stat_h))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b4391",
   "metadata": {},
   "source": [
    "# Loss during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f31fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loss_filename = \"samplewise_metrics_10_600_wimgsums.npy\"\n",
    "\n",
    "results_path = os.path.join(\"MNIST\", \"results\")\n",
    "data_loss_path = os.path.join(results_path, data_loss_filename)\n",
    "\n",
    "data_loss = np.load(data_loss_path, allow_pickle=True)\n",
    "data_loss = np.array(data_loss.item()['samplewise_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db927d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame(index=id_new)\n",
    "\n",
    "loss_df[\"loss__last\"] = data_loss[-1]\n",
    "\n",
    "loss_df[\"loss__var_from_0\"] = data_loss[0:].var(axis=0)\n",
    "loss_df[\"loss__var_from_20\"] = data_loss[20:].var(axis=0)\n",
    "loss_df[\"loss__var_from_50\"] = data_loss[50:].var(axis=0)\n",
    "\n",
    "loss_df[\"loss__mean_from_0\"] = data_loss[0:].mean(axis=0)\n",
    "loss_df[\"loss__mean_from_20\"] = data_loss[20:].mean(axis=0)\n",
    "loss_df[\"loss__mean_from_50\"] = data_loss[50:].mean(axis=0)\n",
    "\n",
    "loss_df[\"loss__std_from_0\"] = data_loss[0:].std(axis=0)\n",
    "loss_df[\"loss__std_from_20\"] = data_loss[20:].std(axis=0)\n",
    "loss_df[\"loss__std_from_50\"] = data_loss[50:].std(axis=0)\n",
    "\n",
    "loss_df[\"loss__diff_last_0\"] = data_loss[-1]-data_loss[0]\n",
    "loss_df[\"loss__diff_last_20\"] = data_loss[-1]-data_loss[20]\n",
    "loss_df[\"loss__diff_last_50\"] = data_loss[-1]-data_loss[50]\n",
    "\n",
    "loss_df.to_csv('metrics_losses_600.csv',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8234b8a7",
   "metadata": {},
   "source": [
    "## Std of loss from i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed8828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data_loss[0:,:-3000].std(axis=0), bins=100);\n",
    "plt.hist(data_loss[0:,-3000:].std(axis=0), bins=100);\n",
    "plt.legend([\"Original\", 'Distorted'])\n",
    "plt.title(f'Std of loss from {0} epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a97783",
   "metadata": {},
   "source": [
    "## Loss value at i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e99fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_plot = np.random.choice(data_loss.shape[1], size=50, replace=False, )\n",
    "\n",
    "plt.figure(figsize=(20,3))\n",
    "plt.plot(data_loss[:, idx_plot])\n",
    "plt.title(\"Loss of AE of randomly sampled objects\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa87fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.hist(data_loss[i,:-3000], bins=100);\n",
    "    plt.hist(data_loss[i,-3000:], bins=100);\n",
    "    plt.title(f\"Loss of AE at {i} epoch\")\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(data_loss), interval=50)\n",
    "from IPython.display import HTML\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc61d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_plot = data_loss[-1]\n",
    "\n",
    "plot_img_zoom_for_stat__imghist(\n",
    "    stat_values=stat_plot,\n",
    "    thr_l=stat_plot.min(),\n",
    "    thr_r=stat_plot.max(),\n",
    "    name_stat=\"Std after 7th epoch (epochs) of loss per sample (emb_size) of samples\",\n",
    "    figsize=(70,25),\n",
    "    N_IMG_ZOOM=60,\n",
    "    N_IMG_PER_ZOOM=15,\n",
    "    log_hist_y=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d2f60a",
   "metadata": {},
   "source": [
    "## Mean of loss from i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data_loss[0:,:-3000].mean(axis=0), bins=100);\n",
    "plt.hist(data_loss[0:,-3000:].mean(axis=0), bins=100);\n",
    "plt.title(f\"Mean of loss of AE from {0} epoch\")\n",
    "plt.legend([\"Original\", 'Distorted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e25e89",
   "metadata": {},
   "source": [
    "## Var of loss from i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce788e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.title(i)\n",
    "    plt.hist(data_loss[i:,:-3000].var(axis=0), bins=100);\n",
    "    plt.hist(data_loss[i:,-3000:].var(axis=0), bins=100);\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(data_loss), interval=50)\n",
    "from IPython.display import HTML\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d8bcc2",
   "metadata": {},
   "source": [
    "## Difference bw last and i losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9504c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plt.title(i)\n",
    "    plt.hist(data_loss[-1,:-3000]-data_loss[i,:-3000], bins=100);\n",
    "    plt.hist(data_loss[-1,-3000:]-data_loss[i,-3000:], bins=100);\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"Original\", 'Distorted'])\n",
    "    \n",
    "    \n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(data_loss))\n",
    "from IPython.display import HTML\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ker_infoplane_v2",
   "language": "python",
   "name": "ker_infoplane_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
